from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory
from langchain.chat_models import ChatOpenAI
from langchain_teddynote.models import MultiModal
from dotenv import load_dotenv
from AlbaGPT_main import alba_task_type_list, dynamic_object_list

import json
import csv
import cv2
import os
import numpy as np
import uuid
import time

load_dotenv()

def alba_task_discriminator(user_query, alba_task_type_list=alba_task_type_list):
    """
    ì•Œë°”ë´‡ì—ê²Œ ì…ë ¥ëœ í”„ë¡¬í”„íŠ¸ê°€ ì–´ë–¤ typeì˜ ëª…ë ¹ì¸ì§€ êµ¬ë¶„í•´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.
    
    Returns : 
        MAINTENANCE, GREETINGS, CAMERA_ON, none ì¤‘ í•˜ë‚˜
    """
    task_example_csv_path = './contents/example/task_example.csv' # ìœ ì € í”„ë¡¬í”„íŠ¸ì— ë”°ë¥¸ ë¶„ë¥˜ëœ taskë¥¼ ì •ë¦¬í•œ csv íŒŒì¼
    fields = []
    task_example_list = []

    with open(task_example_csv_path, 'r') as csvfile:
        csvreader = csv.reader(csvfile)
        fields = next(csvreader)
    
        for row in csvreader:
            task_example_list.append({
                "prompt": row[0],
                "result": row[1]
            })
    
    task_example = "\n".join(
        f'{{"prompt": "{task["prompt"]}", "result": "{task["result"]}"}}'
        for task in task_example_list
    )

    discriminator_prompt = """
    ë‹¹ì‹ ì€ ë ˆìŠ¤í† ë‘ì—ì„œ ì—…ë¬´ë¥¼ í•˜ëŠ” ì¹´ë©”ë¼ê°€ ì¥ì°©ëœ 'í•‘í‚¤'ë¼ëŠ” ì´ë¦„ì„ ê°€ì§„ ëª¨ë°”ì¼ ë¡œë´‡ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì€ ì˜¤ë„ˆì˜ ë‹¤ìŒ ìš”ì²­ì„ ë³´ê³ , ê·¸ê²ƒì´ ì¸ì‚¬(greeting)ì¸ì§€, ì‘ì—… ëª…ë ¹(task command)ì¸ì§€ êµ¬ë¶„í•´ì•¼ í•©ë‹ˆë‹¤.

    ë‹¤ìŒ ìš”ì²­: {user_query}
    
    íŒë‹¨ ê¸°ì¤€ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

    1. ìš”ì²­ì´ ì¸ì‚¬ì¸ ê²½ìš° â†’ ì •í™•íˆ **"GREETINGS"** ë¼ê³ ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    2. ìš”ì²­ì´ ì‘ì—… ëª…ë ¹ì¼ ê²½ìš° â†’ í•´ë‹¹ ì‘ì—…ì´ {alba_task_type_list} ë°°ì—´ ì›ì†Œ ì¤‘ ë¬´ì—‡ì¸ì§€ íŒë‹¨í•˜ê³ , í•´ë‹¹ íƒœìŠ¤í¬ ì´ë¦„ë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    3. ë§Œì•½ "ë¬´ì—‡ì´ ë³´ì´ëƒ", "ë³´ì´ëŠ” ê²ƒì„ ì„¤ëª…í•´ë‹¬ë¼"ëŠ” ìš”ì²­ì´ í¬í•¨ëœë‹¤ë©´, **CAMERA_ON**ìœ¼ë¡œ ê°„ì£¼í•˜ì„¸ìš”. ì´ ê²½ìš° 'ì¹´ë©”ë¼'ë¼ëŠ” ë‹¨ì–´ê°€ ì—†ì–´ë„ ë¬´ì¡°ê±´ CAMREA_ONìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”.
    4. {alba_task_type_list}ì˜ ë°°ì—´ì— ì—†ëŠ” ì›ì†Œì— ëŒ€í•´ì„œëŠ” **"none"**ì„ ì¶œë ¥í•˜ì„¸ìš”.

    ì´ë•Œ ì•„ë˜ ì¡°ê±´ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”:
    - ì¶œë ¥ì€ ë°˜ë“œì‹œ **ëŒ€ë¬¸ì** ë‹¨ì–´ í•˜ë‚˜ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
    - ì¶”ê°€ ì„¤ëª…, ë¬¸ì¥, ë‹¤ë¥¸ ë‹¨ì–´ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    - ê°€ëŠ¥í•œ í•œ ëª…í™•í•˜ê³  ë‹¨ì •ì ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”.
    - ì„¤ëª…, ë¬¸ì¥, êµ¬ë‘ì ì€ ë‹µë³€ìœ¼ë¡œ ë‚´ë†“ì§€ ì•Šì•„ìš”.

    ì •ë‹µ ì˜ˆì‹œ:
    {task_example}
    """

    discriminator_template = PromptTemplate(
        template=discriminator_prompt,
        input_variables=["user_query", "alba_task_type_list", "task_example"],
    )

    # ê°ì²´ ìƒì„±
    llm = ChatOpenAI(
        temperature=0.3,  # ì°½ì˜ì„± (0.0 ~ 2.0)
        max_tokens=2048,  # ìµœëŒ€ í† í°ìˆ˜
        model_name="gpt-4o-mini",  # ëª¨ë¸ëª…
    )

    chain = LLMChain(
        llm=llm,
        prompt=discriminator_template
    )

    discriminated_task = chain.invoke({
        "user_query": user_query,
        "alba_task_type_list": alba_task_type_list,
        "task_example": task_example
    })['text']

    discriminated_task = discriminated_task.replace(".", "").strip()
    
    return discriminated_task
"""

"""
def validate_alba_task_discriminator(user_query, alba_task_type_list=alba_task_type_list):
    """
    alba_task_discriminator í•¨ìˆ˜ë¡œ êµ¬ë¶„í•œ taskê°€ alba_task_type_list ë°°ì—´ì˜ ì›ì†Œ ì¤‘ í•˜ë‚˜ê°€ ë§ëŠ” ì§€ í•œ ë²ˆ ë” íŒë³„í•´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Returns : 
        alba_task_type_listì— ìˆëŠ” ê²½ìš° : {discriminated_task}
        alba_task_type_listì— ì—†ëŠ” ê²½ìš° : None
    """
    discriminated_task = alba_task_discriminator(user_query)
    
    if discriminated_task not in alba_task_type_list :
        return None
    else :
        return discriminated_task

def generate_alba_greetings_response(user_query, chat_history, memory):
    """
    alba_task_discriminator í•¨ìˆ˜ë¡œ êµ¬ë¶„ëœ taskê°€ 'GREETINGS'ì¸ ê²½ìš° user_queryì— ëŒ€í•´ ëŒ€ë‹µì„ ìƒì„±í•˜ì—¬ jsonìœ¼ë¡œ ë°˜í™˜í•´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Returns : JSON outputs
        {{
            "pinky_id" : {pinky_id},
            "pinky_task" : GREETINGS,
            "pinky_response" : {alba_greetings_response}
        }}
    """
    greetings_example_csv_path = './contents/example/greetings_example.csv' # GREETINGS ìƒí™©ì— ëŒ€í•œ ì‘ë‹µì„ ì •ë¦¬í•œ csv íŒŒì¼
    fields = []
    greetings_example_list = []

    with open(greetings_example_csv_path, 'r') as csvfile:
        # creating a csv reader object
        csvreader = csv.reader(csvfile)
        
        # extracting field names through first row
        fields = next(csvreader)
    
        # extracting each data row one by one
        for row in csvreader:
            greetings_example_list.append({
            "prompt": row[0],
            "pinky_id": row[1],
            "pinky_task": row[2],
            "pinky_response": row[3]
        })
            
    greetings_example = "\n".join(
        f'{{"prompt": "{GREETINGS["prompt"]}", "pinky_id": "{GREETINGS["pinky_id"]}", "pinky_task": "{GREETINGS["pinky_task"]}", "pinky_response": "{GREETINGS["pinky_response"]}"}}'
        for GREETINGS in greetings_example_list
    )

    alba_greetings_prompt = """
    ë‹¹ì‹ ì€ ë ˆìŠ¤í† ë‘ì—ì„œ ì—…ë¬´ë¥¼ í•˜ëŠ” 'í•‘í‚¤'ë¼ëŠ” ì´ë¦„ì„ ê°€ì§„ ëª¨ë°”ì¼ ë¡œë´‡ì…ë‹ˆë‹¤
    ì§€ê¸ˆê¹Œì§€ ë‹¹ì‹ ê³¼ ë ˆìŠ¤í† ë‘ ì˜¤ë„ˆê°€ ë‚˜ëˆˆ ëŒ€í™”ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ : {chat_history}

    ë‹¹ì‹ ì€ ë ˆìŠ¤í† ë‘ ì˜¤ë„ˆì˜ {user_query}ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ìƒëƒ¥í•˜ê²Œ, 1~3ì¤„ ì´ë‚´ë¡œ ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ ë‹µë³€í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.

    ì¶œë ¥ ì˜ˆì‹œ:
    {greetings_example}

    ì•„ë˜ì˜ [ì¡°ê±´]ì— ë§ê²Œ [íƒ¬í”Œë¦¿] í˜•ì‹ìœ¼ë¡œ JSON ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”:

    [ì¡°ê±´]
    1. pinky_idëŠ” "Xë²ˆ í•‘í‚¤!"ì—ì„œì˜ X ì…ë‹ˆë‹¤. ì´ë•Œ Xê°€ ì—†ìœ¼ë©´ pinky_idëŠ” ë¹„ì›Œë‘ì„¸ìš”.
    2. pinky_taskëŠ” ë¬´ì¡°ê±´ stringí˜• "GREETINGS" ì…ë‹ˆë‹¤.
    3. pinky_responseëŠ” {user_query}ì— ëŒ€í•œ stringí˜• ë‹µë³€ì…ë‹ˆë‹¤.
    4. ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
    5. ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹(ì˜ˆ: ```json, ``` ë˜ëŠ” ''' ë“±)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
    6. JSON ê°ì²´ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë¬¸ìì—´ ì•ë’¤ ê³µë°± ì™¸ì—ëŠ” ì•„ë¬´ê²ƒë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    7. ìœ„ì˜ ì¡°ê±´ ì´ì™¸ì— ë‹¤ë¥¸ ì •ìˆ˜, ë‹¨ì–´, ë¬¸ì¥ì€ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    [íƒ¬í”Œë¦¿] : ë°˜ë“œì‹œ í°ë”°ì˜´í‘œë¡œ ê°ì‹¸ì„œ ë¬¸ìì—´ í˜•íƒœë¡œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ë¬¸ìì—´ ì´ì™¸ì˜ í˜•ì‹ì€ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. '''json ê°™ì€ ë§ˆí¬ë‹¤ìš´ì€ ì ˆëŒ€ í¬í•¨í•˜ë©´ ì•ˆë©ë‹ˆë‹¤.
    {{
        "pinky_id": "",
        "pinky_task": "",
        "pinky_response": "",
    }}
    """

    alba_greetings_template = PromptTemplate(
        template=alba_greetings_prompt,
        input_variables=["user_query", "chat_history", "greetings_example"]
    )

    # ê°ì²´ ìƒì„±
    llm = ChatOpenAI(
        temperature=0.3,  # ì°½ì˜ì„± (0.0 ~ 2.0)
        max_tokens=2048,  # ìµœëŒ€ í† í°ìˆ˜
        model_name="gpt-4o-mini",  # ëª¨ë¸ëª…
    )

    chain = LLMChain(
        llm=llm,
        prompt=alba_greetings_template,
        memory=memory,
        verbose=True
    )

    alba_greetings_response = chain.invoke({
        "user_query": user_query,
        "chat_history": chat_history,
        "greetings_example": greetings_example
    })['text']

    try:
        alba_greetings_response = json.loads(alba_greetings_response)
    except json.JSONDecodeError:
        raise ValueError(f"âŒ Invalid JSON format: {alba_greetings_response}")

    csvfile.close()
    return alba_greetings_response

def generate_alba_maintenance_response(user_query, chat_history, memory):
    """
    alba_task_discriminator í•¨ìˆ˜ë¡œ êµ¬ë¶„ëœ taskê°€ 'MAINTENANCE'ì¸ ê²½ìš° user_queryì— ëŒ€í•´ ëŒ€ë‹µì„ ìƒì„±í•˜ì—¬ jsonìœ¼ë¡œ ë°˜í™˜í•´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Returns : JSON outputs
        {{
            "pinky_id": {pinky_id},
            "pinky_task": MAINTENANCE
            "pinky_response": {alba_maintenance_response},
        }}
    """
    maintenance_example_csv_path = './contents/example/maintenance_example.csv' # maintenance ìƒí™©ì— ëŒ€í•œ ì‘ë‹µì„ ì •ë¦¬í•œ csv íŒŒì¼
    fields = []
    maintenance_example_list = []

    with open(maintenance_example_csv_path, 'r') as csvfile:
        # creating a csv reader object
        csvreader = csv.reader(csvfile)
        
        # extracting field names through first row
        fields = next(csvreader)
    
        # extracting each data row one by one
        for row in csvreader:
            maintenance_example_list.append({
            "prompt": row[0],
            "pinky_id": row[1],
            "pinky_task": row[2],
            "pinky_response": row[3],
        })
            
    maintenance_example = "\n".join(
        f'{{"prompt": "{maintenance["prompt"]}", "pinky_id": "{maintenance["pinky_id"]}", "pinky_task": "{maintenance["pinky_task"]}", "pinky_response": "{maintenance["pinky_response"]}"}}'
        for maintenance in maintenance_example_list
    )

    alba_maintenance_prompt = """
    ë‹¹ì‹ ì€ ë ˆìŠ¤í† ë‘ì—ì„œ ì—…ë¬´ë¥¼ í•˜ëŠ” 'í•‘í‚¤'ë¼ëŠ” ì´ë¦„ì„ ê°€ì§„ ëª¨ë°”ì¼ ë¡œë´‡ì…ë‹ˆë‹¤
    ì§€ê¸ˆê¹Œì§€ ë‹¹ì‹ ê³¼ ë ˆìŠ¤í† ë‘ ì˜¤ë„ˆê°€ ë‚˜ëˆˆ ëŒ€í™”ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ : {chat_history}

    ë‹¹ì‹ ì€ ë ˆìŠ¤í† ë‘ ì˜¤ë„ˆì˜ {user_query}ì— ëŒ€í•´ {chat_history}ì™€ ì—°ê´€ì´ ìˆë‹¤ë©´ ì°¸ê³ í•˜ì—¬ "MAINTENANCE"ë¼ëŠ” ì—…ë¬´ë¥¼ ìˆ˜í–‰í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì€ {user_query}ì— ëŒ€í•´ì„œ 1~3ì¤„ ì´ë‚´ë¡œ ì§§ê³  ê°„ê²°í•˜ê²Œ ë‹µë³€í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.

    ì¶œë ¥ ì˜ˆì‹œ:
    {maintenance_example}

    ì•„ë˜ì˜ [ì¡°ê±´]ì— ë§ê²Œ [íƒ¬í”Œë¦¿] í˜•ì‹ìœ¼ë¡œ JSON ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”:

    [ì¡°ê±´]
    1. pinky_idëŠ” "Xë²ˆ í•‘í‚¤!"ì—ì„œì˜ X ì…ë‹ˆë‹¤. ì´ë•Œ Xê°€ ì—†ìœ¼ë©´ pinky_idëŠ” ë¹„ì›Œë‘ì„¸ìš”.
    2. pinky_taskëŠ” ë¬´ì¡°ê±´ stringí˜• "MAINTENANCE" ì…ë‹ˆë‹¤.
    3. pinky_responseëŠ” {user_query}ì— ëŒ€í•œ stringí˜• ë‹µë³€ì…ë‹ˆë‹¤.
    4. ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
    5. ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹(ì˜ˆ: ```json, ``` ë˜ëŠ” ''' ë“±)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
    6. JSON ê°ì²´ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë¬¸ìì—´ ì•ë’¤ ê³µë°± ì™¸ì—ëŠ” ì•„ë¬´ê²ƒë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    7. ìœ„ì˜ ì¡°ê±´ ì´ì™¸ì— ë‹¤ë¥¸ ì •ìˆ˜, ë‹¨ì–´, ë¬¸ì¥ì€ ìƒì„±í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

    [íƒ¬í”Œë¦¿] : ë°˜ë“œì‹œ í°ë”°ì˜´í‘œë¡œ ê°ì‹¸ì„œ ë¬¸ìì—´ í˜•íƒœë¡œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ë¬¸ìì—´ ì´ì™¸ì˜ í˜•ì‹ì€ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. '''json ê°™ì€ ë§ˆí¬ë‹¤ìš´ì€ ì ˆëŒ€ í¬í•¨í•˜ë©´ ì•ˆë©ë‹ˆë‹¤.
    {{
        "pinky_id": "",
        "pinky_task": "MAINTENANCE",
        "pinky_response": "",
    }}
    """

    alba_maintenance_template = PromptTemplate(
        template=alba_maintenance_prompt,
        input_variables=["user_query", "chat_history", "maintenance_example"]
    )

    # ê°ì²´ ìƒì„±
    llm = ChatOpenAI(
        temperature=0.3,  # ì°½ì˜ì„± (0.0 ~ 2.0)
        max_tokens=2048,  # ìµœëŒ€ í† í°ìˆ˜
        model_name="gpt-4o-mini",  # ëª¨ë¸ëª…
    )

    chain = LLMChain(
        llm=llm,
        prompt=alba_maintenance_template,
        memory=memory,
        verbose=True
    )

    alba_maintenance_response = chain.invoke({
        "user_query": user_query,
        "chat_history": chat_history,
        "maintenance_example" : maintenance_example
    })['text']


    try:
        alba_maintenance_response = json.loads(alba_maintenance_response)
    except json.JSONDecodeError:
        raise ValueError(f"âŒ Invalid JSON format: {alba_maintenance_response}")

    return alba_maintenance_response 

def generate_alba_camera_on_response(chat_history, shared_dict):
    """
    alba_task_discriminator í•¨ìˆ˜ë¡œ êµ¬ë¶„ëœ taskê°€ 'CAMERA_ON'ì¸ ê²½ìš° í•´ë‹¹ ì•Œë°” ë´‡ìœ¼ë¡œë¶€í„° ìˆ˜ì‹ ë˜ëŠ” ì˜ìƒì˜ ì´ë¯¸ì§€ í”„ë ˆì„ì„ í† ëŒ€ë¡œ ìƒí™©ì„ í•´ì„í•˜ì—¬ jsonìœ¼ë¡œ ë°˜í™˜í•´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Returns : JSON outputs
        {{
            "pinky_id" : {pinky_id},
            "pinky_task" : CAMERA_ON,
            "pinky_response" : {alba_camera_on_response}
        }}
    """
    recieved_image_dir = './contents/image'

    if not os.path.exists(recieved_image_dir) :
        os.makedirs(recieved_image_dir)

    recieved_image_path = os.path.join(recieved_image_dir, str(uuid.uuid4().hex) + '_' + time.strftime('%Y-%m-%d %H-%M-%S') + '.jpg')
    detected_objects = shared_dict["detected_object"]
    latest_frame = shared_dict["latest_frame"]

    detected_object_list = []

    for detected_object in detected_objects :
        detected = detected_object.categories[0].category_name
        detected_object_list.append(detected)

    print(discriminate_obstacle(detected_object_list))

    np_data = np.frombuffer(latest_frame, dtype=np.uint8)
    decoded_detected_image = cv2.imdecode(np_data, cv2.IMREAD_COLOR)

    if decoded_detected_image is None:
        raise ValueError("âŒ Failed to decode image from decoded_detected_image")

    cv2.imwrite(recieved_image_path, decoded_detected_image)
    print(f"â­•ï¸ Image successfully saved to {recieved_image_path}")

    object_info = ', '.join(detected_object_list)

    obstacle_example_csv_path = './contents/example/obstacle_example.csv' # CAMREA ON ìƒí™©ì— ëŒ€í•œ ì‘ë‹µì„ ì •ë¦¬í•œ csv íŒŒì¼
    fields = []
    obstacle_response_example_list = []

    with open(obstacle_example_csv_path, 'r') as csvfile:
        # creating a csv reader object
        csvreader = csv.reader(csvfile)
        
        # extracting field names through first row
        fields = next(csvreader)
    
        # extracting each data row one by one
        for row in csvreader:
            obstacle_response_example_list.append({
            "response": row[0],
        })
            
    obstacle_meetup_example = "\n".join(
        f'{{"response": "{obstacle_response_example["response"]}"}}'
        for obstacle_response_example in obstacle_response_example_list
    )

    user_prompt = f"""
    ì•„ë˜ëŠ” ê°ì§€ëœ ì‚¬ë¬¼ ëª©ë¡ì…ë‹ˆë‹¤: {object_info}
    ì´ ì‚¬ë¬¼ë“¤ì€ ê²½ë¡œë¥¼ ê°€ë¡œë§‰ê³  ìˆìŠµë‹ˆë‹¤.

    ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
    1. ì´ ì‚¬ë¬¼ë“¤ì— ëŒ€í•´ ë°˜ë“œì‹œ "{object_info} {obstacle_meetup_example}" ì™€ ê°™ì€ ì‹ìœ¼ë¡œ ì¬ë¯¸ìˆê²Œ ì„¤ëª…í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
    2. ì¤‘ë³µë˜ëŠ” {object_info}ì— ëŒ€í•´ì„œëŠ” í•œ ë²ˆë§Œ ëŒ€ë‹µí•©ë‹ˆë‹¤.
    3. ë§Œì•½ {object_info}ê°€ nullì¸ ê²½ìš° "ì•„ë¬´ ë¬¸ì œ ì—†ì´ ì„ë¬´ë¥¼ ì˜ ìˆ˜í–‰í•˜ê³  ìˆì–´ìš” ğŸ¤—"ì™€ ê°™ì€ ì‹ìœ¼ë¡œ ì„¤ëª…í•˜ì—¬ì•¼ í•©ë‹ˆë‹¤.
    4. ë‹µë³€ì€ 1-3ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """

    multimodal_system_prompt = f"""
    ë‹¹ì‹ ì€ ë ˆìŠ¤í† ë‘ì—ì„œ ì—…ë¬´ë¥¼ í•˜ëŠ” 'í•‘í‚¤'ë¼ëŠ” ì´ë¦„ì„ ê°€ì§„ ëª¨ë°”ì¼ ë¡œë´‡ì…ë‹ˆë‹¤
    ì§€ê¸ˆê¹Œì§€ ë‹¹ì‹ ê³¼ ë ˆìŠ¤í† ë‘ ì˜¤ë„ˆê°€ ë‚˜ëˆˆ ëŒ€í™”ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ : {chat_history}

    ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ë ˆìŠ¤í† ë‘ ì˜¤ë„ˆì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê³  ìƒëƒ¥í•˜ê²Œ ë‹µë³€í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
    
    ì•„ë˜ì˜ [ì¡°ê±´]ì— ë§ê²Œ [íƒ¬í”Œë¦¿] í˜•ì‹ìœ¼ë¡œ JSON ë‹µë³€ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
    '''json ê°™ì€ ë§ˆí¬ë‹¤ìš´ì€ ì ˆëŒ€ í¬í•¨í•˜ë©´ ì•ˆë©ë‹ˆë‹¤.

    [ì¡°ê±´]
    1. pinky_idëŠ” "Xë²ˆ í•‘í‚¤ ì¹´ë©”ë¼ ì¼œë´"ì—ì„œ X ì…ë‹ˆë‹¤. ì´ë•Œ Xê°€ ì—†ìœ¼ë©´ pinky_idëŠ” ë¹„ì›Œë‘ì„¸ìš”.
    2. pinky_taskëŠ” ë¬´ì¡°ê±´ stringí˜• "CAMERA_ON" ì…ë‹ˆë‹¤.
    3. pinky_responseëŠ” ì•„ë˜ ì‚¬ìš©ì ìš”ì²­ì— ëŒ€í•œ stringí˜• ë‹µë³€ì…ë‹ˆë‹¤.
    4. ì¶œë ¥ì€ ë°˜ë“œì‹œ JSON í˜•ì‹ì˜ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.
    5. ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´ í˜•ì‹(ì˜ˆ: ```json, ``` ë˜ëŠ” ''' ë“±)ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
    6. JSON ê°ì²´ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë¬¸ìì—´ ì•ë’¤ ê³µë°± ì™¸ì—ëŠ” ì•„ë¬´ê²ƒë„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

    [íƒ¬í”Œë¦¿] : ë°˜ë“œì‹œ í°ë”°ì˜´í‘œë¡œ ê°ì‹¸ì„œ ë¬¸ìì—´ í˜•íƒœë¡œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ë¬¸ìì—´ ì´ì™¸ì˜ í˜•ì‹ì€ ì¶œë ¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. '''json ê°™ì€ ë§ˆí¬ë‹¤ìš´ì€ ì ˆëŒ€ í¬í•¨í•˜ë©´ ì•ˆë©ë‹ˆë‹¤.
    {{
        "pinky_id": "",
        "pinky_task": "CAMREA_ON",
        "pinky_response": "",
    }}

    [ì‚¬ìš©ì ìš”ì²­]
    {user_prompt}
    """

    # ê°ì²´ ìƒì„±
    llm = ChatOpenAI(
        temperature=0.7,  # ì°½ì˜ì„± (0.0 ~ 2.0)
        max_tokens=2048,  # ìµœëŒ€ í† í°ìˆ˜
        model_name="gpt-4o",  # ëª¨ë¸ëª…
    )

    multimodal_llm = MultiModal(llm, system_prompt=multimodal_system_prompt, user_prompt=user_prompt)

    alba_camera_on_response = multimodal_llm.invoke(recieved_image_path)
    alba_camera_on_response = alba_camera_on_response.strip().strip('"""').strip()

    try:
        alba_camera_on_response = json.loads(alba_camera_on_response)
    except json.JSONDecodeError:
        raise ValueError(f"Invalid JSON format: {alba_camera_on_response}")        

    return alba_camera_on_response

def discriminate_obstacle(detected_object_list) :
    """
    ê²€ì¶œëœ ì¥ì• ë¬¼ì´ ë™ì  ì¥ì• ë¬¼ì¸ì§€, ì •ì  ì¥ì• ë¬¼ì¸ì§€ íŒë³„í•˜ì—¬ jsonìœ¼ë¡œ ë°˜í™˜í•´ì£¼ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤.

    Returns : JSON outputs
        {{
            "type": "dynamic / static"
        }}
    """

    if not detected_object_list:
        return {"type": ""}  # ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´

    for obj in detected_object_list:
        if obj in dynamic_object_list:
            return {"type": "dynamic"}  # í•˜ë‚˜ë¼ë„ dynamicì´ë©´ dynamic

    return {"type": "static"}  # ëª¨ë‘ staticì¼ ê²½ìš°

def save_alba_response(task, alba_response) :
    """
    AlbaGPTê°€ ë‚´ë†“ì€ jsoní˜• ì‘ë‹µì„ response ë””ë ‰í† ë¦¬ì— json íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ì…ë‹ˆë‹¤. 
    """

    alba_response_dir = './contents/response'

    if not os.path.exists(alba_response_dir) :
        os.makedirs(alba_response_dir)

    if task == "GREETINGS" :
        greetings_file_path = os.path.join(alba_response_dir, 'GREETINGS' + '_response.json')

        with open(greetings_file_path, 'a', encoding="UTF-8") as json_writer:
            json.dump(alba_response, json_writer, indent=4, ensure_ascii=False)
            json_writer.write('\n\n')
            print(f"â­•ï¸ Alba response successfully saved to {greetings_file_path}")
        
        json_writer.close()

    elif task == "CAMERA_ON" :
        CAMREA_ON_file_path = os.path.join(alba_response_dir, 'CAMERA_ON' + '_response.json')

        with open(CAMREA_ON_file_path, 'a', encoding="UTF-8") as json_writer:
            json.dump(alba_response, json_writer, indent=4, ensure_ascii=False)
            json_writer.write('\n\n')
            print(f"â­•ï¸ Alba response successfully saved to {CAMREA_ON_file_path}")
        
        json_writer.close()
    
    else :
        maintenance_file_path = os.path.join(alba_response_dir, 'MAINTENANCE' + '_response.json')

        with open(maintenance_file_path, 'a', encoding="UTF-8") as json_writer:
            json.dump(alba_response, json_writer, indent=4, ensure_ascii=False)
            json_writer.write('\n\n')
            print(f"â­•ï¸ Alba response successfully saved to {maintenance_file_path}")
        
        json_writer.close()        
    return
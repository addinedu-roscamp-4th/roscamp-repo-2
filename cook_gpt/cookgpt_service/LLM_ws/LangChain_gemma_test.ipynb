{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d3b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_teddynote.messages import stream_response\n",
    "\n",
    "import time\n",
    "\n",
    "# Ollama 모델을 불러옵니다.\n",
    "llm = ChatOllama(model=\"gemma3:12b\")\n",
    "\n",
    "# 프롬프트\n",
    "prompt = ChatPromptTemplate.from_template(\"{topic} 에 대하여 간략히 설명해 줘.\")\n",
    "\n",
    "# 질의 내용\n",
    "summarize_prompt = f\"\"\"\n",
    "다음은 한 매장의 최근 운영 데이터를 요약한 내용입니다.\n",
    "아래 [데이터]를 기반으로 매장의 현재 상황을 분석하고, 문제가 있다면 그 원인을 추론해 주세요.\n",
    "또한 아래 [요청사항]을 기반으로 매장의 개선을 위한 구체적인 전략도 제안해 주세요.\n",
    "\n",
    "영어로 답변해주세요.\n",
    "\n",
    "[데이터]\n",
    "\n",
    "일평균 방문 고객 수: 320명 → 최근 일주일간 270명으로 감소\n",
    "\n",
    "평균 고객 체류 시간: 25분\n",
    "\n",
    "점심 시간(12시~2시) 매출: 일 평균 대비 35% 감소\n",
    "\n",
    "최근 한 달간 리뷰 평점: 4.5점 → 3.8점\n",
    "\n",
    "직원 2명 퇴사 → 대체 인력 미배치\n",
    "\n",
    "\n",
    "[요청사항]\n",
    "\n",
    "위 데이터를 기반으로 매장의 현재 상황을 진단해 주세요.\n",
    "\n",
    "어떤 문제가 발생하고 있는지, 그 원인이 무엇인지 추론해 주세요.\n",
    "\n",
    "이를 개선하기 위한 실행 전략을 제안해 주세요.\n",
    "\"\"\"\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# response = llm.invoke(prompt)\n",
    "response = llm.stream(summarize_prompt)\n",
    "stream_response(response)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa84dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-2. LLM 모델이 이전 대화를 기억하도록 하기\n",
    "\n",
    "from langchain_teddynote.messages import stream_response\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 메모리 생성 (기록 저장용)\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key=\"user_query\")\n",
    "\n",
    "# 질의 내용\n",
    "pinky_prompt = \"\"\"\n",
    "당신은 레스토랑을 돌아다니는 '핑키'라는 이름을 가진 모바일 로봇입니다.\n",
    "지금까지의 대화는 다음과 같습니다 : {chat_history}\n",
    "\n",
    "당신의 임무는 레스토랑 오너의 {user_query}에 대해 {chat_history}를 기반으로 친절하고 진실되게 답변하는 것입니다.\n",
    "또한 당신은 {user_query}에 대해 2~3줄 이내로 짧고 간결하게 답변하여야 합니다.\n",
    "\"\"\"\n",
    "\n",
    "pinky_template = PromptTemplate(template = pinky_prompt, input_variables=[\"chat_history\", \"user_query\"])\n",
    "\n",
    "# Ollama 모델을 불러옵니다.\n",
    "llm = ChatOllama(model=\"gemma3:12b\")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=pinky_template,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
